---
title: "Inferential Stats with R"
output:
  xaringan::moon_reader:
    css: ["style.css", "default"]
    lib_dir: libs
    df_print: paged
    nature:
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
      ratio: 16:9
---

```{r child = "setup.Rmd"}
```
```{r packages, include = F, eval = T}
library(tidyverse)
library(skimr)
library(summarytools)

college <- read_csv("../Data/college.csv")
```


class: center, middle, dk-section-title

# Welcome to the Course!

---


## What you will learn in this course

???

This course will cover seven topics. 
1. First, we're going to learn four main inferential statistics...

5. We'll also learn how to conduct reliability such as Cronbach's alpha, a measure of internal consistency.

6. Then we'll learn how to report statistics in R through learning how to extract values from the summary output, tidying up the results, and using packages to report statistics easily.

7. Lastly, we'll cover how to test assumptions of your parametric tests and what to do if you do not meet the assumptions of normally distributed data. 

--

1. t-tests: independent and dependent

--

2. ANOVA: mainly the one-way ANOVA

--

3. chi-square

--

4. regression

--

5. reliability (internal consistency)

--

6. how to report statistics in R

--

7. how to test parametric assumptions

---

## What you will need for this course

-- 

1. R and RStudio!

--

2. Dataset: college.csv

--

3. Packages: [insert packages here]
  + broom
  + apa
  + psych
  + lm.beta
  + etc.
  
---

## How this course will work

---

class: center, middle, dk-section-title

# Introduction to the dataset

---

## college.csv

```{r eval = TRUE}
college <- read_csv("../Data/college.csv")

college 
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[2:5], style = "grid", valid.col = FALSE, caption = FALSE, graph.magnif = 1.2,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[6:9], style = "grid", valid.col = FALSE, caption = FALSE, graph.magnif = 1.2,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[c(10:11, 14)], style = "grid", valid.col = FALSE, caption = FALSE,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[15:18], style = "grid", valid.col = FALSE, caption = FALSE,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

## Satisfaction with Life Scale

```{r eval = TRUE, echo = FALSE, results = 'asis', rows.print = 10}
college %>%
  select(19:28) %>%
  summarytools::descr(., stats = c("mean", "min", "max"), headings = FALSE) %>%
  tb()
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[29:31], style = "grid", valid.col = FALSE, caption = FALSE,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

class:inverse

## Your Turn

You'll be working with the college dataset to run all your analyses. 

--

1. Create a new project. Make sure you put it somehwere you'll be able to find it again later!

--

1. Download the dataset "college.csv"

--

1. Create a new R script file where you'll do all of your inferential statistics

--

1. Import the spreadsheet into a dataframe `college`

---

class: center, middle, dk-section-title

# t-tests

---

## Independent vs dependent t-test

.pull-left[
### Independent t-test

- Between-subjects
- Independent samples
- Examine the mean difference between two unrelated groups (e.g., males and females, a group of mothers and a group of daughters)
]

--

.pull-right[
### Dependent t-test

- Within-subjects
- Dependent or paired samples
- Examine the mean difference between two related groups (e.g., same group at two time points, pairs of mothers and daughters)
]

--

Both t-tests are performed using the `t.test()` function in the **stats** package

---

### Independent t-test

```{r}
dat %>%
  t.test(DV ~ IV, .)
```

???

This is the basic syntax of the independent t-test using the tidyverse. There are a lot of other arguments in the t.test function that we'll slowly learn about. 

---

### Independent t-test

```{r}
dat %>%
  t.test(DV ~ IV, `.`)
```

???

One of the arguments is the data argument. In the t.test function, the dataset argument comes second. This is why the dot comes second instead of first.

--

```{r}
dat %>%
  t.test(., DV ~ IV)
```

--

`## Error: Can't combine id <character> and athlete <double>.`

???

If you put the dot first, indicating to put the dataset at the beginning, it won't work

---

### Independent t-test

Let's try running an independent samples t-test with our `college` dataset. 

--

```{r}
college %>%
  t.test(weight_2 ~ smokes, .)
```

--

```{r eval = TRUE, echo = FALSE}
college %>%
  t.test(weight_2 ~ smokes, .)
```

--

The t-test defaults to assuming the variances between groups is *not* equal.

---

### Variances Equal

```{r}
college %>%
  t.test(weight_2 ~ smokes, ., `var.equal = TRUE`)
```

???

Add the argument `var.equal = TRUE` to specify that we assume the variances between groups is equal.

--

```{r eval = TRUE, echo = FALSE}
college %>%
  t.test(weight_2 ~ smokes, ., var.equal = TRUE)
```

---

### Alternative hypothesis

The default alternative hypothesis is a **two-sided hypothesis** that the mean difference is not equal to 0. 

```{r}
college %>%
  t.test(weight_2 ~ smokes, ., var.equal = TRUE, `alternative = "two.sided"`)
```

--

What if you have a **one-sided hypothesis**? 

--

```{r}
college %>%
  t.test(weight_2 ~ smokes, ., var.equal = TRUE, `alternative = "greater"`)
```

```{r}
college %>%
  t.test(weight_2 ~ smokes, ., var.equal = TRUE, `alternative = "less"`)
```

???

The alternative argument lets you specify either **less** or **greater** than 0. 

---

### Alternative hypothesis

.pull-left[
```{r, eval = TRUE}
college %>%
  t.test(weight_2 ~ smokes, ., 
         var.equal = TRUE, 
         alternative = "two.sided")
```
]

--

.pull-right[
```{r, eval = TRUE}
college %>%
  t.test(weight_2 ~ smokes, ., 
         var.equal = TRUE, 
         alternative = "greater")
```
]

???

Notice that the p-value is half of the previous value of .2305. 

---

### Other arguments in the t-test
.pull-left[
```{r}
college %>%
  t.test(weight_2 ~ smokes, ., 
         `mu = 1`)
```
```{r eval = TRUE, echo = FALSE}
college %>%
  t.test(weight_2 ~ smokes, ., 
         mu = 1)
```
]

???

mu is a greek symbol for the population mean, or in this case the mean difference that we're testing for. It defaults at 0, but you can change it to any value to test whether the mean difference is mu.

--

.pull-right[
```{r}
college %>%
  t.test(weight_2 ~ smokes, ., 
         `conf.level = .99`)
```
```{r eval = TRUE, echo = FALSE}
college %>%
  t.test(weight_2 ~ smokes, ., 
         conf.level = .99)
```
]

???

You can also adjust the confidence intervals to be from the default 95% confidence interval to something else, such as a 99% confidence interval.

---

class: inverse

### Your Turn

--

1. Open the R project for this course and your R markdown file. Run the beginning of your script so you have the `college` dataset available in your R environment.

--

1. Perform an independent samples t-test to test whether there is a difference in `exam_1` by `athlete`. Use `var.equal = TRUE`. Is there a difference? What is the p-value? 

--

1. Filter your dataset to only people who have the `political` party of Democrat or Republican. Perform an independent samples t-test to test whether there is a difference in `age` by `political` party. Use `var.equal = TRUE`. Is there a difference? What is the p-value? 

```{r, include = FALSE}

### T-TEST ANSWERS

## 2 ##
college %>%
  t.test(exam_1 ~ athlete, ., var.equal = TRUE)

## 3 ##
college %>%
  filter(political != "Other") %>%
  t.test(age ~ political, ., var.equal = FALSE)
```

---

## Dependent t-test

---

### Independent vs dependent t-test

.pull-left[
### Independent t-test

- Between-subjects
- Independent samples
- Examine the mean difference between two unrelated groups (e.g., males and females, a group of mothers and a group of daughters)
]

.pull-right[
### Dependent t-test

- Within-subjects
- Dependent or paired samples
- Examine the mean difference between two related groups (e.g., same group at two time points, pairs of mothers and daughters)
]

---

### Dependent t-test

The dependent t-test adds a new argument to the `t.test` function: 

.center[`paired = TRUE`]

--

.pull-left[
```{r}
t.test(`dat$DV1, dat$DV2`, 
       paired = TRUE)
```


Used when the data are in **wide** format.

Each *case or pair* is a row, and the DV is in two different columns.
(This is most common.)

<font size = "3">Note that piping the dataset doesn't work here. You have to explicitly type out data$DV.</font>
]

--

.pull-right[
```{r}
dat %>%
  t.test(`DV ~ IV`, paired = TRUE, .)
```
Used when the data are in **long** format.

Each *observation* is a row, and the DV is in one column and the case or pair ID is in another column.
]

???

This is the basic syntax of the dependent t-test using the tidyverse. Notice the inclusion of paired = TRUE argument. This tells R the data is a paired samples or dependent samples t-test. 

There are two ways of inputting the data. If your data is in wide format, with each person representing a row and two columns of data per person, then you'll use the first set of code. However, if your data is in long format, with each person's data at two time points representing a row (therefore having double the rows of data) then you'll use the second set of code. 

---

### Dependent t-test

```{r}
t.test(college$weight_1, college$weight_2, paired = TRUE)
```

--

```{r, eval = TRUE, echo = FALSE, highlight.output = 5}
t.test(college$weight_1, college$weight_2, paired = TRUE)
```

---

### Converting wide to long format

```{r}
college %>%
  select(weight_1, weight_2) %>%
  pivot_longer(cols = starts_with("weight"), 
               names_to = "time",
               values_to = "weight",
               names_prefix = "weight_") %>%
  `t.test(weight ~ time, data = ., paired = TRUE)`
```

--

```{r, eval = TRUE, echo = FALSE, highlight.output = 5}
college %>%
  select(weight_1, weight_2) %>%
  pivot_longer(cols = starts_with("weight"), 
               names_to = "time",
               values_to = "weight",
               names_prefix = "weight_") %>%
  t.test(weight ~ time, data = ., paired = TRUE)
```

---

class: inverse

### Your Turn

--

1. Open the R project for this course and your R markdown file. Run the beginning of your script so you have the `college` dataset available in your R environment.

--

1. Perform a  dependent samples t-test to test whether there is a difference in exam scores: `exam_1` and `exam_2`. Is there a difference? What is the p-value? 

--

1. Perform a dependent samples t-test to test whether there is a difference in `act_english` and `act_reading` scores. Is there a difference? What is the p-value?

--

**Bonus!!!**

Using `pivot_longer` pivot your data so it is in long form. Perform a dependent samples t-test to test whether there is a difference in `act_science` and `act_english` scores using the long-data t.test code.

```{r, include = FALSE}

### T-TEST ANSWERS

## 2 ##
t.test(college$exam_1, college$exam_2, paired = TRUE)

## 3 ##
t.test(college$act_english, college$act_reading, paired = TRUE)

## BONUS ##
college %>%
  select(act_science, act_english) %>%
  pivot_longer(cols = starts_with("act"), 
               names_to = "act",
               values_to = "score",
               names_prefix = "act_") %>%
  t.test(score ~ act, data = ., paired = TRUE)

```


---

# One-way ANOVA

---

## One-way ANOVA

- Between-subjects

--

- Independent samples

--

- Examine the mean difference between **three or more** unrelated groups

--

- Tests the null hypothesis that the three or more means are the same

--

- To know *where* the mean differences are, we need planned contrasts or post-hoc procedures like Tukey's HSD (we'll cover that in the next video)

---

### One-way ANOVA in R

```{r}
dat %>%
  aov(DV ~ IV, data = .) %>%
  summary()
```

---

### An example

```{r, eval = TRUE}
college %>%
  aov(exam_1 ~ grade_class, data = .)
```

--

The output is not very useful. For that reason, we need to store the output into a model and ask for the summary of the model. 

---

### An example

```{r}
college %>%
  aov(exam_1 ~ grade_class, data = .) %>%
  summary() #<<
```

-- 

```{r, eval = TRUE, echo = FALSE}
college %>%
  aov(exam_1 ~ grade_class, data = .) %>%
  summary()
```

```{r, eval = TRUE, echo = FALSE}
modelsummary <- summary(aov(exam_1 ~ grade_class, data = college))
```

The `summary()` output provides the F-value (`r round(modelsummary[[1]]$"F value"[1], 2)`), df (`r modelsummary[[1]]$Df`), and p-value (`r round(modelsummary[[1]]$"Pr(>F)"[1], 3)`) you need to report the statistical values. 

---

class: inverse

### Your Turn

--

1. Open the R project for this course and your R markdown file. Run the beginning of your script so you have the `college` dataset available in your R environment.

--

1. Perform one-way ANOVA to test whether there is a difference in `hs_gpa` by `grade_class`. Is there a difference? What is the p-value? 

--

1. Previously, you performed a t-test between Democrats and Republicans to see if there is a difference in age between the two groups. Now, using all three groups of `political`, test whether there is a difference in `age`. Is there a difference? What is the p-value? 

```{r include = FALSE}

### ONE-WAY ANOVA ANSWERS

## 2 ##
college %>%
  aov(hs_gpa ~ grade_class, data = .) %>%
  summary()

## 3 ##
college %>%
  aov(age ~ political, data = .) %>%
  summary()
```
