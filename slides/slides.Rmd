---
title: "Inferential Stats with R"
output:
  xaringan::moon_reader:
    css: ["style.css", "default"]
    lib_dir: libs
    df_print: paged
    nature:
      highlightStyle: github
      highlightLines: true
      highlightSpans: true
      countIncrementalSlides: false
      ratio: 16:9
---

```{r child = "setup.Rmd"}
```
```{r packages, include = F, eval = T}
library(tidyverse)
library(skimr)
library(summarytools)
library(janitor)

college <- read_csv("../Data/college.csv")
```


class: center, middle, dk-section-title

# Welcome to the Course!

---


## What you will learn in this course

???

This course will cover seven topics. 
1. First, we're going to learn four main inferential statistics...

5. We'll also learn how to conduct reliability such as Cronbach's alpha, a measure of internal consistency.

6. Then we'll learn how to report statistics in R through learning how to extract values from the summary output, tidying up the results, and using packages to report statistics easily.

7. Lastly, we'll cover how to test assumptions of your parametric tests and what to do if you do not meet the assumptions of normally distributed data. 

--

1. t-tests: independent and dependent

--

2. ANOVA: mainly the one-way ANOVA

--

3. chi-square

--

4. regression

--

5. reliability (internal consistency)

--

6. how to report statistics in R

--

7. how to test parametric assumptions

---

## What you will need for this course

-- 

1. R and RStudio!

--

2. Dataset: college.csv

--

3. Packages: [insert packages here]
  + broom
  + apa
  + psych
  + lm.beta
  + etc.
  
---

## How this course will work

---

class: center, middle, dk-section-title

# Introduction to the dataset

---

## college.csv

```{r eval = TRUE}
college <- read_csv("../Data/college.csv")

college 
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[2:5], style = "grid", valid.col = FALSE, caption = FALSE, graph.magnif = 1.2,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[6:9], style = "grid", valid.col = FALSE, caption = FALSE, graph.magnif = 1.2,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[c(10:11, 14)], style = "grid", valid.col = FALSE, caption = FALSE,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[15:18], style = "grid", valid.col = FALSE, caption = FALSE,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

## Satisfaction with Life Scale

```{r eval = TRUE, echo = FALSE, results = 'asis', rows.print = 10}
college %>%
  select(19:28) %>%
  summarytools::descr(., stats = c("mean", "min", "max"), headings = FALSE) %>%
  tb()
```

---

```{r eval = TRUE, echo = FALSE, results = 'asis'}
st_css()
print(dfSummary(college[29:31], style = "grid", valid.col = FALSE, caption = FALSE,
                varnumbers = FALSE, na.col = FALSE, headings = FALSE), method = 'render')
```

---

class:inverse

## Your Turn

You'll be working with the college dataset to run all your analyses. 

--

1. Create a new project. Make sure you put it somehwere you'll be able to find it again later!

--

1. Download the dataset "college.csv"

--

1. Create a new R script file where you'll do all of your inferential statistics

--

1. Import the spreadsheet into a dataframe `college`

---

class: center, middle, dk-section-title

# Independent t-test

---

## Independent vs dependent t-test

.pull-left[
### Independent t-test

- Between-subjects
- Independent samples
- Examine the mean difference between two unrelated groups (e.g., males and females, a group of mothers and a group of daughters)
]

--

.pull-right[
### Dependent t-test

- Within-subjects
- Dependent or paired samples
- Examine the mean difference between two related groups (e.g., same group at two time points, pairs of mothers and daughters)
]

--

Both t-tests are performed using the `t.test()` function in the **stats** package

---

## Independent t-test in R

```{r}
dat %>%
  t.test(DV ~ IV, .)
```

???

This is the basic syntax of the independent t-test using the tidyverse. There are a lot of other arguments in the t.test function that we'll slowly learn about. 

---

## Independent t-test in R

```{r}
dat %>%
  t.test(DV ~ IV, `.`)
```

???

One of the arguments is the data argument. In the t.test function, the dataset argument comes second. This is why the dot comes second instead of first.

--

```{r}
dat %>%
  t.test(., DV ~ IV)
```

--

`## Error: Can't combine id <character> and athlete <double>.`

???

If you put the dot first, indicating to put the dataset at the beginning, it won't work

---

## An example

Let's try running an independent samples t-test with our `college` dataset. 

--

```{r}
college %>%
  t.test(weight_2 ~ smokes, .)
```

--

```{r eval = TRUE, echo = FALSE}
college %>%
  t.test(weight_2 ~ smokes, .)
```

--

The t-test defaults to assuming the variances between groups is *not* equal.

---

## Variances Equal

```{r}
college %>%
  t.test(weight_2 ~ smokes, ., `var.equal = TRUE`)
```

???

Add the argument `var.equal = TRUE` to specify that we assume the variances between groups is equal.

--

```{r eval = TRUE, echo = FALSE}
college %>%
  t.test(weight_2 ~ smokes, ., var.equal = TRUE)
```

---

## Alternative hypothesis

The default alternative hypothesis is a **two-sided hypothesis** that the mean difference is not equal to 0. 

```{r}
college %>%
  t.test(weight_2 ~ smokes, ., var.equal = TRUE, `alternative = "two.sided"`)
```

--

What if you have a **one-sided hypothesis**? 

--

```{r}
college %>%
  t.test(weight_2 ~ smokes, ., var.equal = TRUE, `alternative = "greater"`)
```

```{r}
college %>%
  t.test(weight_2 ~ smokes, ., var.equal = TRUE, `alternative = "less"`)
```

???

The alternative argument lets you specify either **less** or **greater** than 0. 

---

## Alternative hypothesis

.pull-left[
```{r, eval = TRUE}
college %>%
  t.test(weight_2 ~ smokes, ., 
         var.equal = TRUE, 
         alternative = "two.sided")
```
]

--

.pull-right[
```{r, eval = TRUE}
college %>%
  t.test(weight_2 ~ smokes, ., 
         var.equal = TRUE, 
         alternative = "greater")
```
]

???

Notice that the p-value is half of the previous value of .2305. 

---

## Other arguments in the t-test
.pull-left[
```{r}
college %>%
  t.test(weight_2 ~ smokes, ., 
         `mu = 1`)
```
```{r eval = TRUE, echo = FALSE}
college %>%
  t.test(weight_2 ~ smokes, ., 
         mu = 1)
```
]

???

mu is a greek symbol for the population mean, or in this case the mean difference that we're testing for. It defaults at 0, but you can change it to any value to test whether the mean difference is mu.

--

.pull-right[
```{r}
college %>%
  t.test(weight_2 ~ smokes, ., 
         `conf.level = .99`)
```
```{r eval = TRUE, echo = FALSE}
college %>%
  t.test(weight_2 ~ smokes, ., 
         conf.level = .99)
```
]

???

You can also adjust the confidence intervals to be from the default 95% confidence interval to something else, such as a 99% confidence interval.

---

class: inverse

## Your Turn

--

1. Open the R project for this course and your R markdown file. Run the beginning of your script so you have the `college` dataset available in your R environment.

--

1. Perform an independent samples t-test to test whether there is a difference in `exam_1` by `athlete`. Use `var.equal = TRUE`. Is there a difference? What is the p-value? 

--

1. Filter your dataset to only people who have the `political` party of Democrat or Republican. Perform an independent samples t-test to test whether there is a difference in `age` by `political` party. Use `var.equal = TRUE`. Is there a difference? What is the p-value? 

```{r, include = FALSE}

### T-TEST ANSWERS

## 2 ##
college %>%
  t.test(exam_1 ~ athlete, ., var.equal = TRUE)

## 3 ##
college %>%
  filter(gender != "Trans*") %>%
  t.test(act_english ~ gender, ., var.equal = FALSE)
```

---

class: center, middle, dk-section-title

# Dependent t-test

---

## Independent vs dependent t-test

.pull-left[
### Independent t-test

- Between-subjects
- Independent samples
- Examine the mean difference between two unrelated groups (e.g., males and females, a group of mothers and a group of daughters)
]

.pull-right[
### Dependent t-test

- Within-subjects
- Dependent or paired samples
- Examine the mean difference between two related groups (e.g., same group at two time points, pairs of mothers and daughters)
]

---

## Dependent t-test in R

The dependent t-test adds a new argument to the `t.test` function: 

.center[`paired = TRUE`]

--

.pull-left[
```{r}
t.test(`dat$DV1, dat$DV2`, 
       paired = TRUE)
```


Used when the data are in **wide** format.

Each *case or pair* is a row, and the DV is in two different columns.
(This is most common.)

<font size = "3">Note that piping the dataset doesn't work here. You have to explicitly type out data$DV.</font>
]

--

.pull-right[
```{r}
dat %>%
  t.test(`DV ~ IV`, paired = TRUE, .)
```
Used when the data are in **long** format.

Each *observation* is a row, and the DV is in one column and the case or pair ID is in another column.
]

???

This is the basic syntax of the dependent t-test using the tidyverse. Notice the inclusion of paired = TRUE argument. This tells R the data is a paired samples or dependent samples t-test. 

There are two ways of inputting the data. If your data is in wide format, with each person representing a row and two columns of data per person, then you'll use the first set of code. However, if your data is in long format, with each person's data at two time points representing a row (therefore having double the rows of data) then you'll use the second set of code. 

---

## An example

```{r}
t.test(college$weight_1, college$weight_2, paired = TRUE)
```

--

```{r, eval = TRUE, echo = FALSE, highlight.output = 5}
t.test(college$weight_1, college$weight_2, paired = TRUE)
```

---

## Converting wide to long format

```{r}
college %>%
  select(weight_1, weight_2) %>%
  pivot_longer(cols = starts_with("weight"), 
               names_to = "time",
               values_to = "weight",
               names_prefix = "weight_") %>%
  `t.test(weight ~ time, data = ., paired = TRUE)`
```

--

```{r, eval = TRUE, echo = FALSE, highlight.output = 5}
college %>%
  select(weight_1, weight_2) %>%
  pivot_longer(cols = starts_with("weight"), 
               names_to = "time",
               values_to = "weight",
               names_prefix = "weight_") %>%
  t.test(weight ~ time, data = ., paired = TRUE)
```

---

class: inverse

## Your Turn

--

1. Open the R project for this course and your R markdown file. Run the beginning of your script so you have the `college` dataset available in your R environment.

--

1. Perform a  dependent samples t-test to test whether there is a difference in exam scores: `exam_1` and `exam_2`. Is there a difference? What is the p-value? 

--

1. Perform a dependent samples t-test to test whether there is a difference in `act_science` and `act_mathematics` scores. Is there a difference? What is the p-value?

--

**Bonus!!!**

Using `pivot_longer` pivot your data so it is in long form. Perform a dependent samples t-test to test whether there is a difference in `act_science` and `act_english` scores using the long-data t.test code.

```{r, include = FALSE}

### T-TEST ANSWERS

## 2 ##
t.test(college$exam_1, college$exam_2, paired = TRUE)

## 3 ##
t.test(college$act_science, college$act_mathematics, paired = TRUE)

## BONUS ##
college %>%
  select(act_science, act_english) %>%
  pivot_longer(cols = starts_with("act"), 
               names_to = "act",
               values_to = "score",
               names_prefix = "act_") %>%
  t.test(score ~ act, data = ., paired = TRUE)

```


---

class: center, middle, dk-section-title

# One-way ANOVA

---

## One-way ANOVA

- Between-subjects

--

- Independent samples

--

- Examine the mean difference between **three or more** unrelated groups

--

- Tests the null hypothesis that the three or more means are the same

--

- To know *where* the mean differences are, we need planned contrasts or post-hoc procedures like Tukey's HSD (we'll cover that in the next video)

---

## One-way ANOVA in R

```{r}
dat %>%
  `aov`(DV ~ IV, data = .) %>%
  summary()
```

The formatting for the one-way ANOVA is similar to that of `t.test` except we replace it with `aov`.

---

## An example

```{r, eval = TRUE}
college %>%
  aov(exam_1 ~ grade_class, data = .)
```

--

The output is not very useful. For that reason, we need to ask for the summary of the model. 

---

## An example

```{r}
college %>%
  aov(age ~ grade_class, data = .) %>%
  summary() #<<
```

--

```{r, eval = TRUE, echo = FALSE}
college %>%
  aov(age ~ grade_class, data = .) %>%
  summary()
```

```{r, eval = TRUE, echo = FALSE}
modelsummary <- summary(aov(age ~ grade_class, data = college))
```

The `summary()` output provides the F-value (`r round(modelsummary[[1]]$"F value"[1], 2)`), df (`r modelsummary[[1]]$Df`), and p-value (`r round(modelsummary[[1]]$"Pr(>F)"[1], 3)`) you need to report the statistical values. 

The summary will add asterisks if there are any statistically significant p-values (e.g., `‘*’ 0.05`).

---

class: inverse

## Your Turn

--

1. Open the R project for this course and your R markdown file. Run the beginning of your script so you have the `college` dataset available in your R environment.

--

1. Perform a one-way ANOVA to test whether there is a difference in `hs_gpa` by `grade_class`. Is there a difference? What is the p-value? 

--

1. Perform a one-way ANOVA to test whether there is a difference in `act_english` by `race`. Is there a difference? What is the p-value? 

```{r include = FALSE}

### ONE-WAY ANOVA ANSWERS

## 2 ##
college %>%
  aov(hs_gpa ~ grade_class, data = .) %>%
  summary()

## 3 ##
college %>%
  aov(act_english ~ race, data = .) %>%
  summary()
```

---

class: center, middle, dk-section-title

# Post hoc comparisons

---

## Post hoc comparisons

The one-way ANOVA tests the null hypothesis that there is no mean difference between the 3+ groups. If the one-way ANOVA is statistically significant, it does not tell us *where* the differences lie.

--

For that, we need post hoc comparisons.*

--

There are many post hoc comparisons possible (e.g., Fisher's LSD, Bonferroni, Newman-Keuls, Scheffe), but we're going to focus on **Tukey's HSD** because it's easy to calculate and does a good job protecting against Type I errors without being too conservative. 

??

Tukey's Honest Significant Differences

---

## Tukey's HSD

```{r}
dat %>%
  aov(DV ~ IV, data = .) %>%
  `TukeyHSD()`
```

---

## An example

```{r}
college %>%
  aov(act_reading ~ gender, data = .) %>%
  summary()
```

--

```{r, eval = TRUE, echo = FALSE}
college %>%
  aov(act_reading ~ gender, data = .) %>%
  summary()
```

---

## An example

```{r}
college %>%
  aov(act_reading ~ gender, data = .) %>%
  TukeyHSD()
```

--

```{r, eval = TRUE, echo = FALSE, highlight.output = 8}
college %>%
  aov(act_reading ~ gender, data = .) %>%
  TukeyHSD()
```

--

Female students tend to have higher ACT reading scores than male students. There are no differences in ACT reading scores between male and female students with Trans* students.

---

class: inverse

## Your Turn

--

1. Open the R project for this course and your R markdown file. Run the beginning of your script so you have the `college` dataset available in your R environment.

--

1. Perform one-way ANOVA to test whether there is a difference in `hs_gpa` by `grade_class`. Is there a difference? If so, perform a Tukey's HSD to test where the differences are. Describe the differences.

--

1. Perform one-way ANOVA to test whether there is a difference in `weight_1` by `gender`. Is there a difference? If so, perform a Tukey's HSD to test where the differences are. Describe the differences. 

```{r include = FALSE}

### ONE-WAY ANOVA ANSWERS

## 2 ##
college %>%
  aov(hs_gpa ~ grade_class, data = .) %>%
  summary()
# No Tukey's HSD because there is no statistically significant difference.

## 3 ##
college %>%
  aov(weight_1 ~ gender, data = .) %>%
  summary()

college %>%
  aov(weight_1 ~ gender, data = .) %>%
  TukeyHSD
# 
```

---

class: center, middle, dk-section-title

# Other ANOVA tests

---

## Repeated measures ANOVA

Repeated Measures ANOVA allows us to examine designs in which the same people or samples contributed to the different means (within-groups design). This means that all participants or cases participated in all conditions of an experiment or IV. 

**Example**: Let's examine how exam scores (`exam_1`, `exam_2`, and `exam_3`) differ within individuals across time. 

---

### An example

First, we need to convert our data to long format.

```{r}
college %>%
  select(starts_with("exam"), id) %>%
  pivot_longer(cols = starts_with("exam"), 
               names_to = "exam",
               values_to = "score",
               names_prefix = "exam_")
```

--

```{r, eval = TRUE, echo = FALSE}
college %>%
  select(starts_with("exam"), id) %>%
  pivot_longer(cols = starts_with("exam"), 
               names_to = "exam",
               values_to = "score",
               names_prefix = "exam_")
```

---

### An example

Then we can run our repeated measures ANOVA.

```{r}
college %>%
  select(starts_with("exam"), id) %>%
  pivot_longer(cols = starts_with("exam"), 
               names_to = "exam",
               values_to = "score",
               names_prefix = "exam_") %>%
  aov(score ~ exam + Error(id), data = .) %>% #<<
  summary() #<<
```

--

```{r, eval = TRUE, echo = FALSE, highlight.output = 8}
college %>%
  select(starts_with("exam"), id) %>%
  pivot_longer(cols = starts_with("exam"), 
               names_to = "exam",
               values_to = "score",
               names_prefix = "exam_") %>%
  aov(score ~ exam + Error(id), data = .) %>%
  summary()
```

---

## Factorial ANOVA

Factorial ANOVA allows us to examine two or more independent variables (IVs) simultaneously. There are several types of factorial designs:

--

- **Independent factorial design**: 2+ between-group (independent) IVs 

--

-	**Repeated measures factorial design**: 2+ within-group (repeated-measures) IVs

--

-	**Mixed factorial design**: 1+ between-group and 1+ within-group IVs

---

## Factorial ANOVA

To perform a factorial ANOVA in R, all you need to do is add more variables to the right hand of the tilde (~) in the ANOVA equation using either a + (does not add an interaction term) or * (adds an interaction term).

---

## Example independent factorial design

```{r, eval = TRUE}
college %>% aov(weight_1 ~ gender + smokes, data = .) %>% summary() # NO INTERACTION
```

--

```{r, eval = TRUE}
college %>% aov(weight_1 ~ gender * smokes, data = .) %>% summary() #  INTERACTION 
```

---

class: inverse

## Your Turn

--

Read more about how to conduct repeated measures and factorial ANOVA designs using the resources below.






---

class: center, middle, dk-section-title

# Chi-square

---

## Chi-square

The chi-square test is used to analyze categorical data (data that describe categories of entities). We can't examine categorical data using things like means or medians, so we examine counts instead. 

--

```{r}
college %>% 
  tabyl(live_on_campus, athlete)
```

--

```{r, eval = TRUE, echo = FALSE}
college %>% 
  tabyl(live_on_campus, athlete)
```


---

## Chi-square in R

Two methods: the `janitor` package or the `stats` package

--

.pull-left[
###Janitor Package
```{r, eval = TRUE, highlight.output = 5}
college %>%
  tabyl(smokes, athlete) %>%
  janitor::chisq.test()
```

]

--

.pull-right[
###stats Package
```{r, eval = TRUE, highlight.output = 5}
stats::chisq.test(college$smokes, college$athlete)
```
]

---

## Standardized Residuals

The standardized residuals tell us for that cell if the expected and observed frequency are independent. They are z-scores so values greater than 1.96 are statistically significant (*p* < .05).

--

```{r}
tab$stdres #<<
```

--

```{r, eval = TRUE, echo = FALSE}
tab <- college %>%
  tabyl(smokes, athlete) %>%
  janitor::chisq.test(.)

tab$stdres
```

---

## Observed and expected counts

Similarly, we can ask for the observed and expected counts.

--

.pull-left[
### Observed
```{r, eval = TRUE}
tab$observed
```
]

--

.pull-left[
### Expected
```{r, eval = TRUE}
tab$expected
```
]

---

class: inverse

## Your Turn

--

1. Open the R project for this course and your R markdown file. Run the beginning of your script so you have the `college` dataset available in your R environment.

--

1. Perform a chi-square to examine how `grade_class` relates to `live_on_campus`. What is the p-value? Is there a relationship?

--

1. If there is a significant difference, examine standardized residuals and the observed/expected frequencies to determine what grade class is more or less likely to live on campus. Interpret the results.

```{r include = FALSE}

### CHI-SQUARE ANSWERS

## 2 ##
tab2 <- college %>%
  tabyl(grade_class, live_on_campus) %>%
  chisq.test()

tab2

## 3 ##
tab2$stdres

tab2$observed

tab2$expected
# 
```

---

class: center, middle, dk-section-title

# Dealing with small cells

---

## Dealing with small cells

Sometimes when dealing with small cells, you will get an error that the Chi-square approximation may not be correct. 

--

Example:

```{r, eval = TRUE, warning = TRUE}
college %>%
  filter(smokes == 1) %>%
  tabyl(race, gender) %>%
  chisq.test()
```

--

There are a few things we can do to fix this problem.

---

## 1. Drop a row or column

--

```{r, eval = TRUE}
college %>%
  filter(smokes == 1) %>%
  tabyl(race, gender)
```

---

## 1. Drop a row or column

```{r, eval = TRUE, warning = TRUE}
college %>%
  filter(smokes == 1) %>%
  filter(gender != "Trans*") %>% #<<
  tabyl(race, gender)
```

---

## 1. Drop a row or column

```{r, eval = TRUE, warning = TRUE}
college %>%
  filter(smokes == 1) %>%
  filter(gender != "Trans*") %>%
  tabyl(race, gender) %>%
  chisq.test()  #<<
```

---

## 2. Combine rows or columns so there are larger cells

--

```{r, eval = TRUE}
college %>%
  filter(smokes == 1) %>%
  tabyl(race, gender)
```
---

## 2. Combine rows or columns so there are larger cells

```{r, eval = TRUE}
college %>%
  filter(smokes == 1) %>%
  mutate(URM = recode(race, "Bi-Racial" = 1,  #<<
                     "Asian" = 0, "White" = 0,  #<<
                     "Black" = 1, "Hispanic" = 1)) %>%  #<<
  tabyl(URM, gender)
```
---

## 2. Combine rows or columns so there are larger cells

```{r, eval = TRUE}
college %>%
  filter(smokes == 1) %>%
  mutate(URM = recode(race, "Bi-Racial" = 1,
                     "Asian" = 0, "White" = 0,
                     "Black" = 1, "Hispanic" = 1)) %>%
  tabyl(URM, gender) %>%
  chisq.test()  #<<
```

---

## 3. Both!

--

```{r, eval = TRUE}
college %>%
  filter(smokes == 1) %>%
  filter(gender != "Trans*") %>%  #<< 
  mutate(URM = recode(race, "Bi-Racial" = 1,  #<<
                     "Asian" = 0, "White" = 0,  #<<
                     "Black" = 1, "Hispanic" = 1)) %>%  #<<
  tabyl(URM, gender)
```

---

## 3. Both!

```{r, eval = TRUE}
college %>%
  filter(smokes == 1) %>%
  filter(gender != "Trans*") %>%
  mutate(URM = recode(race, "Bi-Racial" = 1,
                     "Asian" = 0, "White" = 0,
                     "Black" = 1, "Hispanic" = 1)) %>%
  tabyl(URM, gender) %>%
  chisq.test()  #<<
```